<!DOCTYPE html>
<html>
<head>
  <title>EVA 2.0 â€“ Enhanced Virtual Assistant</title>
</head>
<body>

  <h1>ğŸ¤– EVA 2.0 â€“ Enhanced Virtual Assistant</h1>
  <p>
    EVA is a multimodal AI assistant built with voice, vision, and gesture control. It's designed for natural interaction using FastAPI, Gemini Pro, YOLOv8, and MediaPipe. The frontend (upcoming) will offer a beautiful React.js interface to interact with EVA in real time.
  </p>

  <h2>ğŸš€ Features</h2>
  <ul>
    <li>ğŸ™ï¸ Voice-controlled chatbot using Google Gemini</li>
    <li>ğŸ—£ï¸ Text-to-speech with slow-paced female voice</li>
    <li>ğŸ“· Object detection using YOLOv8</li>
    <li>âœ‹ Hand gesture detection using MediaPipe</li>
    <li>âš¡ Gesture-action mapping (e.g. fist = standby, thumb = scan)</li>
    <li>ğŸ§  EVA introduces herself as a true assistant (not an LLM)</li>
  </ul>

  <h2>ğŸ§  Backend Tech Stack</h2>
  <ul>
    <li>FastAPI (Python)</li>
    <li>Google Generative AI SDK (Gemini)</li>
    <li>SpeechRecognition, PyAudio, pyttsx3</li>
    <li>YOLOv8 (Ultralytics), OpenCV</li>
    <li>MediaPipe for gesture detection</li>
    <li>LangChain + OpenAI (optional fallback)</li>
  </ul>

  <h2>ğŸ¨ Frontend Roadmap (React.js)</h2>
  <ul>
    <li>ğŸ§‘â€ğŸ’» EVA Chat UI with real-time response rendering</li>
    <li>ğŸ¤ Mic button to trigger EVA speech loop</li>
    <li>ğŸ“· Webcam stream panel for gesture + object feedback</li>
    <li>ğŸ–ï¸ Overlay that displays detected gesture + action</li>
    <li>ğŸ§© API status and logs dashboard</li>
    <li>ğŸŒ— Dark mode toggle</li>
  </ul>

  <h2>ğŸ“¦ Installation</h2>
  <pre>
git clone https://github.com/dhruvkajla/eva-2.0.git
cd eva-2.0
pip install -r requirements.txt
  </pre>

  <h2>ğŸ” .env File (Gemini API)</h2>
  <pre>
GOOGLE_API_KEY=your_gemini_api_key_here
  </pre>

  <h2>â–¶ï¸ Running EVA Backend</h2>
  <pre>python app.py</pre>
  <p>Visit: <code>http://localhost:8000/docs</code> for Swagger UI</p>

  <h2>ğŸ“® API Endpoints</h2>
  <ul>
    <li><code>GET /assistant/run</code> â€“ Voice in â†’ Gemini â†’ Speak back</li>
    <li><code>GET /assistant/gesture</code> â€“ Detect gesture only</li>
    <li><code>GET /assistant/gesture-action</code> â€“ Detect gesture and trigger mapped action</li>
    <li><code>GET /assistant/detect-objects</code> â€“ Detect objects from webcam</li>
  </ul>

  <h2>ğŸ“ Project Structure</h2>
  <pre>
eva-2.0/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.html
â”‚
â””â”€â”€ server/
    â””â”€â”€ app/
        â”œâ”€â”€ api/
        â”‚   â”œâ”€â”€ assistant_routes.py
        â”‚   â””â”€â”€ gesture_routes.py
        â”‚
        â”œâ”€â”€ services/
        â”‚   â”œâ”€â”€ chatbot_services.py
        â”‚   â”œâ”€â”€ text_to_speech_service.py
        â”‚   â”œâ”€â”€ speech_recognition_service.py
        â”‚   â”œâ”€â”€ object_detection_service.py
        â”‚   â””â”€â”€ gesture_detection_service.py
  </pre>

  <h2>ğŸ“Œ Future Add-ons</h2>
  <ul>
    <li>ğŸ  Smart home device controls (lights, fans, etc)</li>
    <li>ğŸ“Š Voice command history with timestamps</li>
    <li>ğŸ“ File summarizer using Gemini (upload + answer)</li>
    <li>ğŸ“ Face recognition + calling system integration</li>
    <li>ğŸ§© Plugin system to extend EVA modules (AI doctor, AI tutor, etc)</li>
  </ul>

  <p><strong>ğŸ‘¨â€ğŸ’» Built with love by Dhruv Kajla</strong></p>

</body>
</html>
